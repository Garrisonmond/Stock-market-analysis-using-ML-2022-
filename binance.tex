\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{graphicx}
\usepackage{indentfirst}
\usepackage{amsmath}
\usepackage{hyperref}
%Прогнозирование криптовалютного рынка с помощью машинного обучения%
\title{Предсказание котировок криптовалютных активов с помощью элементов Машинного обучения }
\author{Иван Кузнецов, Георгий Рябов}
\date{Апрель 2022}

\begin{document}
	\maketitle
	
	\section{Введение}
	\paragraph{}
	Криптовалюта — это альтернативное платежное средство. Объемы торгов этим типом активов постоянно растут, а значит интерес с точки зрения прогнозирования растет. Для  стабильного заработка на криптовалютном рынке нужно уметь прогнозировать изменение котировок рынков в будущем, зная показатели рынка в моменте. Для решения такой задачи удобнее всего пользоваться методами Машинного обучения (ML), потому что они наиболее универсальны. Хотя, например, задачу рыночного арбитража, так же свойственную  для этого типа активов, можно решать и стандартным алгоритмическим подходом. [1]
	\paragraph{}
	Предсказание котировок криптовалютных активов с помощью ML требует применения на практике базовых методов машинного обучения и сбора данных. Удобнее всего для таких целей подходит язык программирования Python с его многочисленными библиотеками. Сведем задачу прогнозирования к задаче бинарной классификации, другими словами необходимо предсказать к какому из двух классов: "изменение цены положительно" или "изменение цены отрицательно", — будет относиться цена актива в следующий промежуток времени. Такие изменения часто называют "свечами". Будем ориентироваться на высокочастотную торговлю, предполагающую совершение большого количества сделок в маленький промежуток времени.
	\paragraph{}
	Задача работы доказать или опровергнуть утверждение, что качество ML моделей зависит от количества рассматриваемых свечей, а также отобрать наиболее полезные признаки, по которым можно определить наиболее подходящую ML модель для решения этой задачи.
	\\
	\\
	\\
	\\
	\\Можно выделить соответствующие подзадачи:
	\\
	\\
	- Сбор данных с криптобиржи.\\
	- Обработка данных.\\
	- Обучение ML моделей. \\
	- Сравнение качества ML моделей.
	\section{Сбор данных}
	\paragraph{}
	Для  качественного обучения алгоритма нам нужен большой объем данных. Удобнее всего воспользоваться встроенным API криптобиржи Binance. [2]
	\paragraph{}
	API (Application Programming Interface) -  это специальный интерфейс программирования приложений, позволяющий сервисам взаимодействовать, получать доступ и обмениваться данными. В данном случае API позволяет взаимодействовать с криптобиржей с помощью языка Python. [3] 
	\paragraph{}
	Для получения доступа к этому протоколу мы создали Binance кошелёк, после чего нам стали доступны apikey и secretkey - специальные ключи для взаимодействия с биржей и нашими активами на ней. Далее мы подключили библиотеку python-binance для удобного взаимодействия с функционалом API. Выберем пару активов BTCUSDT, так как именно торги этой парой активов составляют наибольшую часть оборота криптобиржи. 
	Выделим минутные изменения рынка с начала этого года. Сырые данные представляют собой таблицу 1 на странице \pageref{raw}, состоящую из 11 столбцов и 1140000 строк. Данные предстваляют собой свечи.
	\\
	\\
	Столбцы таблицы: 
	\\
	\\
	Open Time - время открытия торгов \\
	Open - цена актива на открытии торгов \\
	High - максимум цены актива за торговую сессию \\
	Low - минимум цены актива за торговую сессию \\
	Close - цена актива на закрытии торгов \\
	Low - минимум цены актива за торговую сессию \\
	Volume - объем торгов за торговую сессию\\
	Сlose Time - время закрытия торгов \\
	Quote Asset Volume - Объем торгов второго элемента пары\\
	Number of Trades - Количество сделок\\
	TB Base Volume - Количество ордеров на покупку первого элемента пары\\
	TB Quote Volume - Количество ордеров на покупку второго элемента пары 
	\paragraph{}
	Этого объема данных достаточно для обучения  алгоритмов бинарной классификации и оценки его качества. 
	\begin{figure}
		\label{raw}
		\includegraphics[width=\textwidth]{1}
		\caption{Транспонированная таблица сырых данных}
	\end{figure}
	\\
	\\
	\section{Обработка данных}
	\paragraph{}
	Перед тем, как обучать ML модели нужно  изучить датасет и определить пространство признаков. Данных у нас очень много, а это неизбежно влечет статистические выбросы и различные ошибки в форматировании. Это все можно сделать с помощью функционала библиотек Pandas и Sckit-Learn. Избавимся от пустых (Not a Number) значений и дубликатов в таблице, изменим тип столбцов. Удалим признак Close Time и сформируем новые признаки, ориентируясь на столбец Open Time выделим день недели (Day of Week), день месяца (Day of Month), номер месяца (Month of Year), номер неделю (Week of Year), час дня (Hour of Day), и минуту (Minute of Hour). Далее вычислим изменение цены в следующий момент времени $Delta = Close - Open$ и сопоставим его текущем. Далее создадим столбец SignDelta применив функцию $f(x) = sign(x)$ к каждому элементу столбца. Исключим из таблицы объекты для которых определить такое целевое значение нельзя. В результате получаем столбец,  элементы которого принимают бинарные значения. Их мы будем предсказывать. Обновленное пространство признаков представлено в таблице 2 на странице \pageref{new}. 
	\\
	\begin{figure}
		\label{new}
		\includegraphics[width=\textwidth]{2}
		\caption{Транспонированная таблица обработанных данных}
	\end{figure}
	\section{Описание ML моделей}
	\paragraph{}
	Рассмотрим наиболее простые модели, которые применяются в решении задач бинарной классификации: логистическая регрессия, метод ближайших соседей, дерево решений и случайный лес.
	\subsection{Логистическая регрессия}
	\paragraph{}
	Логистическая регрессия — это модель, часто используемая для прогнозирования вероятности возникновения некоторого события. 
	\paragraph{}
	Пусть некоторый объект описывается n числовыми признаками$f_j$: X$\to$$\textit{R}$, $\textit{j=1,\ldots,n}$. Тогда пространство признаков объекта есть X $=\textit{R}^n$. Обозначим Y — конечное множество классов.
	Пусть задана выборка, на которой можно обучить модель $X^m$ = $\{(x_1,y_1),\dots,(x_m,y_m)\}.$\\
	\newpage
	Случай двух классов\\
	Положим Y=$\{-1,+1\}$. В логистической регрессии алгоритм классификации: X$\to$Y будет иметь вид:
	
	a(x,w) = $\mathrm{sign}\left( \sum_{j=1}^n w_j f_j(x) - w_0 \right) = \mathrm{sign}\langle x,w \rangle$,
	где $w_j$ — вес j-го признака, $w_0$ — порог принятия решения, w=($w_0$,$w_1$,$\ldots$,$w_n$) — вектор весов. Введем, что искусственный признак для удобства записи: $f_{0}$(x) = - 1.
	
	Обучение линейного классификатора состоит в том, чтобы по ограниченной выборке объектов для обучения $X^m$ найти вектор w. В логистической регрессии это задача сводится к задаче минимизации, где функция потерь выглядит так:
	
	Q(w) = $\sum_{i=1}^m$ $\ln\left( 1 + \exp( -y_i \langle x_i,w \rangle ) \right) \to \min_{w}$
	
	Найденный вектор-w решение, позволяет не только решить задачу классификацию a(x) = $\mathrm{sign}\langle x,w \rangle$ для произвольного объекта x, но и оценивать вероятности его принадлежности к классам:
	
	$\textit{P}\{y|x\} = \sigma\left( y \langle x,w \rangle\right),\;\; y\in Y$,
	
	$ \text{где } \sigma(z) = \dfrac{1}{1+e^{-z}}$  — сигмоидная функция. [4] 
	
	\subsection{Метод ближайших соседей}
	\paragraph{}
	Метод k-ближайших соседей это алгоритм, который применяется для решения задач автоматической классификации объектов или регрессии.
	\paragraph{}
	Если метод используется для классификации, то объекту присваивается тот класс, который является наиболее часто встречается среди k соседей этого объекта. А если метод используется для решения задачи регрессии, то объекту присваивается среднее значение по k ближайших к нему объектам.
	\paragraph{}
	Пусть обучающая выборка выглядит также: \\$X^m$ = $\{(x_1,y_1),\dots,(x_m,y_m)\}$.
	Определим функцию расстояния $\rho(x,x')$. Чем больше становится значение этой функции, тем менее схожи два выбранных объекта x,x'.
	
	Произвольно выберем некоторый объект u, расположим объекты обучающей выборки $x_i$ в порядке не убывания их расстояний до u:
	
	\[\rho(u,x_{1; u})\leq  \rho(u,x_{2; u}) \leq \cdots \leq \rho(u,x_{m; u})\]
	
	где через $x_{i; u}$ обозначается тот объект из выбранной обучающей выборки, который является i-м соседом объекта u. Таким же образом обозначим ответ на i-м соседе: $y_{i; u}$. Получаем
	\begin{center}
		a(u) = arg $\underset{y\in Y}{max}\sum\limits_{i=1}^n[y(x_{i;u})=y](w(i;u))$
	\end{center} 
	В наиболее общем виде алгоритм ближайших выглядит так. [5]
	\subsection{Дерево решений}
	\paragraph{}
	Дерево принятия решений (также называют деревом классификации или регрессионным деревом) — это широко распространенное средство поддержки принятия решений. Дерево представляет собой набор  «листьев» и «веток». На ветках дерева решения расположены признаки, от которых зависит целевая функция, а  в «листьях» определены значения целевой функции. В оставшихся узлах — признаки, по которым различаются случаи. Для классификации нового объекта, необхадимо спуститься по соответствующим ребрам ("веткам") и найти соответствующее значение листа.
	\paragraph{}
	Деревья решений могут быть использованы в качестве математических и вычислительных методов, чтобы помочь описать, которые могут быть записаны следующим образом:\\
	\begin{center}
		$(x, Y) = (x_1, x_2 \dots, x_k, Y)$
	\end{center}
	
	Зависимая переменная Y является целевой, которую необходимо классифицировать. Вектор $x$ состоит из входных переменных $x_1,  x_2,  x_3$ и т. д. Они используются для выполнения этой задачи. [6]
	\subsection{Случайный лес}
	\paragraph{}
	Случайный лес — это распространенный алгоритм машинного обучения, суть которого заключается в создании ансамбля решающих деревьев. Описанный алгоритм не редко применяется в задачах классификации и регрессии. Каждое из деревьев даёт маленькое качество классификации, но за счёт их большого количества результат получается хорошим.
	\paragraph{}
	Кратко опишем алгоритм построения случайного леса, состоящего из $\large N$ деревьев:
	\begin{enumerate}
		\item Сгенерировать выборку $\large X_n$
		\item Построить решающее дерево $\large b_n$ по выборке $\large X_n$:
		\begin{enumerate}
			\item по заданному критерию мы пытаемся определить наилучший признак и продолжать разбиение в дереве уже по нему и так до исчерпания выборки
			\item дерево строится, пока в каждом листе не более $\large n_\text{min}$ объектов или пока не достигнем определенной высоты дерева
			\item при каждом разбиении сначала выбирается $\large m$ случайных признаков из $\large n$ исходных,
			и оптимальное разделение выборки ищется только среди них.
		\end{enumerate}
	\end{enumerate}
	В итоге классификатор выглядит так $\large a(x) = \frac{1}{N}\sum_{i = 1}^N b_i(x)$ [7]
	\section{Обучение ML моделей}
	\paragraph{}
	Изучим зависимость качества модели от глубины данных. Другими словами, будем группировать объекты в таблице в кластеры по 1, 5, 10, 50, 100, 200 штук, увеличивая количество признаков.
	
	
	Для обучения и сравнения ML моделей будем использовать метод кросс-валидаци (Cross-Validation) из библиотеки sklearn. Другими словами, разобьем датасет на 10 частей. Обучим модель на 9 из них, а на оставшейся протестируем. Повторим процедуру 10 раз, каждый раз по очереди меняя часть данных для теста модели. [8]
	
	Воспользуемся объектом MinMaxScaler из библиотеки Sckit-Learn для нормировки пространства признаков. Значение каждой ячейки соответствующего столбца изменится по формуле:
	\[x:=x \cdot (max-min)+min\]
	$x$ - значение элемента столбца\\
	min - минимальное значение элементов столбца\\
	max - максимальное значение элементов столбца
	
	
	Обучим описанные выше модели.
	\section{Сравнение ML моделей}
	\paragraph{}
	Определим параметры, по которым будет проводиться сравнение моделей. Для удобства записи построим таблицу 3 на стр. \pageref{confusion}
	\begin{figure}[h]
		\label{confusion}
		\includegraphics[width=\textwidth]{confusion2}
		\caption{Confusion matrix}
	\end{figure}
	\begin{align*}
		&Accuracy = \frac{TP+TN}{TP+TN+FP+FN}\\
		\\
		&Recall = \frac{TP}{TP+FN}\\
		\\
		&Precision = \frac{TP}{TP+FP}\\
		\\
		& F1 = \frac{Precision\cdot Recall}{Precision + Recall}
	\end{align*}
	Метрика Accuracy показывает долю верно угаданных ответов. Но этого мало, чтобы делать выводы о качестве модели. Имеют место ошибки 1 рода (FN) и ошибки 2 рода (FP). Для их контроля определим Recall и Precision соответственно и возьмем их среднее-гармоническое. Это F1 метрика. [9] Для сравнения качества моделей будем использовать именно F1 метрику, так как она позволяет контролировать ошибки 1 и 2 рода.
	\paragraph{}
	Во время процесса Сross-Validation получаем 10 значений Accuracy, Recall, Precision и F1. Посчитаем их среднее и определим стандартное отклонение. Графики приведены далее.
	\paragraph{}
	По графикам 4 - 10  кажется на стр \pageref{lr_f1_table}, что качество модели выше при обучении на кластере из 100 свечей. Определим, значимо ли это отличие. Проведем проверку статистической гипотезы о равенстве двух средних. Воспользуемся Т-тестом Стьюдента. [10] 
	\paragraph{}
	Импортируем библиотеку scipy для python. Нулевая гипотеза теста — это предположение, что разница качество моделей не значима статистически, и находится на уровне значимости 5\% а альтернативная гипотеза — это предположение, что разница значима статистически. Воспользуемся функцией ttest\_ind и сравним массивы F1 метрик для 1 и 100 свечей для каждой из моделей, полученных в результате кросс-валидации. 
	\begin{figure}[!h]
		\centering
		\label{lr_f1_table}
		\includegraphics[width=0.4\textwidth]{lr_table}
		\hfill
		\includegraphics[width=0.4\textwidth]{knn_table}
		\caption{Логистическая регрессия и Метод ближайших соседей}
		\includegraphics[width=0.4\textwidth]{tree_table}
		\hfill
		\includegraphics[width=0.45\textwidth]{rnd_table3}
		\caption{Дерево решений и Случайный лес}
	\end{figure}
	\paragraph{}
	Результаты теста для всех моделей показывают достигаемый уровень значимости выше 5\%. Таким образом, мы не отвергаем нулевую гипотезу в пользу альтернативы, что свидетельствует, что качество не зависит от глубины данных. 
	\paragraph{}
	Дальнейшее сравнение моделей между собой, в попытках определить какая лучше справляется с поставленной задачей, будем проводить при 100 свечах. Проведем такие же тесты для каждой пары моделей. Нулевую и альтернативную гипотезы сформулируем аналогично. Результаты каждого теста также показывают достигаемый уровень значимости выше 5\%. Отвергать нулевую гипотезу в каждом из этих случае не стоит.
	\section{Выводы}
	\paragraph{}
	В нашей работе мы изучили основы процесса сбора и обработки данных, изучили основные модели машинного обучения, применяемые в задачах бинарной классификации и обучили модель предсказывать знак изменения цены актива на следующем промежутке времени, зная показатели рынка в моменте. Мы пришли к выводу, что различия в качестве моделей не статистически значимо, при рассмотрении разного количества свечей. Различия в качестве модели логистической регрессии, метода ближайших соседей, дерева решений и модели случайного леса в нашей задаче, также оказались незначительны. Скорее всего, это связано с тем, что модели построенные нами слишком просты и не способны уловить сложные зависимости рынка криптовалюты. В перспективе, модели можно улучшать, добавляя дополнительные признаки, основанные на техническом анализе.
	\section{Обязанности}
	\paragraph{}
	Иван Кузнецов выполнил:
	\begin{enumerate}
		\item Выполнил отчистку данных собранных с использованием api Binance.
		\item Применил и обучил модель машинного обучения "Дерево решений".
		\item Применил и обучил модель машинного обучения "Случайный лес".
		\item Сравнил и проанализировал различные модели машинного обучения.
	\end{enumerate}
	
	Георгий Рябов выполнил:
	\begin{enumerate}
		\item Выполнил сбор данных с использованием api Binance.
		\item Выполнил первичный анализ моделей машинного обучения для дальнейшего использования.
		\item Применил и обучил модель машинного обучения "Логистическая регрессия".
		\item Применил и обучил модель машинного обучения "Метод ближайших соседей".
	\end{enumerate}
	\section{Список литературы}
	[1] - \href{https://www.netinbag.com/ru/finance/what-is-market-arbitrage.html}{https://www.netinbag.com}
	
	[2] - \href{https://www.binance.com/ru}{https://www.binance.com/ru}
	
	[3] - \href{https://www.programmableweb.com/glossary/api}{https://www.programmableweb.com}
	
	[4] - \href{http://www.machinelearning.ru/wiki/index.php?title=%D0%9B%D0%BE%D0%B3%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D1%8F}{http://www.machinelearning.ru/wiki/LogisticRegression}
	
	[5] - \href{http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%B1%D0%BB%D0%B8%D0%B6%D0%B0%D0%B9%D1%88%D0%B5%D0%B3%D0%BE_%D1%81%D0%BE%D1%81%D0%B5%D0%B4%D0%B0#:~:text=%D0%9C%D0%B0%D1%82%D0%B5%D1%80%D0%B8%D0%B0%D0%BB%20%D0%B8%D0%B7%20MachineLearning.&text=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4%20%D0%B1%D0%BB%D0%B8%D0%B6%D0%B0%D0%B9%D1%88%D0%B8%D1%85%20%D1%81%D0%BE%D1%81%D0%B5%D0%B4%D0%B5%D0%B9%20%E2%80%94%20%D0%BF%D1%80%D0%BE%D1%81%D1%82%D0%B5%D0%B9%D1%88%D0%B8%D0%B9%20%D0%BC%D0%B5%D1%82%D1%80%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9,%D0%BA%20%D0%BD%D0%B5%D0%BC%D1%83%20%D0%BE%D0%B1%D1%8A%D0%B5%D0%BA%D1%82%D1%8B%20%D0%BE%D0%B1%D1%83%D1%87%D0%B0%D1%8E%D1%89%D0%B5%D0%B9%20%D0%B2%D1%8B%D0%B1%D0%BE%D1%80%D0%BA%D0%B8.}{http://www.machinelearning.ru/wiki/KNearestNeighbors}
	
	[6] - \href{https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html}{https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html}
	
	[7] - \href{https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html}{https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html}
	
	[8] - \href{https://scikit-learn.org/stable/modules/cross_validation.html}{https://scikit-learn.org/stable/modules/cross\_validation.html}
	
	[9] - \href{https://towardsdatascience.com/a-look-at-precision-recall-and-f1-score-36b5fd0dd3ec#:~:text=F1%2Dscore%20when%20Precision%3D0.8%20and%20Recall%20%3D%200.01%20to%201.0&text=Here%20precision%20is%20fixed%20at,varies%20from%200.0%20to%201.0.}{https://towardsdatascience.com}
	
	[10] - \href{https://r-analytics.blogspot.com/2012/03/t.html}{https://r-analytics.blogspot.com}
	\pagebreak
	\section{Дополнительные графики}
	\begin{figure}[h]
		\centering
		\label{lr_accuracy}
		\includegraphics[width=0.7\textwidth]{lr_accuracy}
		\caption{Логистическая регрессия Accuracy}
	\end{figure}
	\begin{figure}[h]
		\centering
		\label{lr_f1}
		\includegraphics[width=0.7\textwidth]{lr_f1}
		\caption{Логистическая регрессия F1}
	\end{figure}
	\begin{figure}[h]
		\centering
		\label{knn_accuracy}
		\includegraphics[width=0.7\textwidth]{knn_accuracy}
		\caption{Метод ближайших соседей Accuracy}
	\end{figure}
	\begin{figure}[h]
		\centering
		\label{knn_f1}
		\includegraphics[width=0.7\textwidth]{knn_f1}
		\caption{Метод ближайших соседей F1}
	\end{figure}
	\begin{figure}[h]
		\centering
		\label{tree_accuracy}
		\includegraphics[width=0.7\textwidth]{tree_accuracy}
		\caption{Дерево решений Accuracy}
	\end{figure}
	\begin{figure}[h]
		\centering
		\label{tree_f1}
		\includegraphics[width=0.7\textwidth]{tree_f1}
		\caption{Дерево решений F1}
	\end{figure}
	\begin{figure}[h]
		\centering
		\label{rnd_accuracy}
		\includegraphics[width=0.7\textwidth]{rnd_accuracy}
		\caption{Случайный лес Accuracy}
	\end{figure}
	\begin{figure}[h]
		\centering
		\label{rnd_f1}
		\includegraphics[width=0.7\textwidth]{rnd_f1}
		\caption{Случайный лес F1}
	\end{figure}
\end{document}